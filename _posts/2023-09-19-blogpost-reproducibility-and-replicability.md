In this short discussion, I will recap the main points posed by Chapter 3 of *Understanding reproducibility and replicability* from the National Academy of Sciences, as well as Rey 2009's *Show me the code: Spatial analysis and open source*.

Additionally, I will reflect on the following, along with other considerations:
1) To what extent does open source GIS help solve the problems of the reproducibility crisis for geography? How?
2) Are there problems with reproducibility and replicability in geography that open source GIS cannot help solve?

More than 230 distinct scientific fields and subfields.  Very specialized published literature.  Use of statistical analysis has expanded across disciplines.

Today's shift towards open science is merely the next step in a trend that has already been happening (ex. shift towards emphasis on randomized experiments with masking and the introduction of rigid experimental and trial protocols in the 1970s).

Democratization of data and computation --> available in all disciplines.

Pressure for researchers/scholars to get published in prestigious journals 

Potential biases of scientists - how do we identify and expose to improve accuracy in research results

The expansion of computational tools in the 1990s engendered propositions to establish expectations that data and code will be openly shared so that results could be reproduced, assuming that reanalysis of the same data with the same methods will yield the same results

Debate over the vocabulary and use of reproducibility vs. replicability:
Reproducibility = includes the act of a scond researcher recomputing the original results using the same data, code, and methods (transparencey and reproducibility of computations)

Replicability = obtaining consistent results across studies aimed at answering the same scienficic question, each of which has obtained its own data (can be the same or different researchers...what matters is collecting new data)

Underlying concepts:
1) are data layed out with sufficient transparency and clarity that the results can be checked?
2) if checked, do the data and analysis offered in support of the result *actually* support that result?
3) if the data and analysis are shown to support the original result, can the result reported be found again in the *specific study context* investigated?
4) can the result reported or the inference drawn be found again in a *broader* set of study contexts?

Variation in methods employed in a study: very slight changes in methodology can often go overlooked (ex. are survey questions conducted via email or over the phone?)

Rigor = strict application of the scientific method to ensure robust and unbiased experimental design

Transparency (of data, code, and computational methods) implies computational reproduccibility of the results.  The clarity, accuracy, specificity, and completeness in the description of study methods directly affects replicability.



